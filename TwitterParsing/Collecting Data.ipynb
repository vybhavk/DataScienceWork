{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-07T21:19:55.352672Z",
     "start_time": "2017-07-07T21:19:55.349600Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dateutil\n",
    "import datetime\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-07T20:34:39.348403Z",
     "start_time": "2017-07-07T20:34:39.340574Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the authentication object\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "# Creating the API object while passing in auth information\n",
    "api = tweepy.API(auth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-07T22:01:45.482600Z",
     "start_time": "2017-07-07T22:01:43.692420Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Confusion Matrix #machinelearningflashcards https://t.co/GVk5CMBAQa',\n",
       "  'Thu Jul 06 19:41:48 +0000 2017'),\n",
       " ('Out-Of-Bag Error #machinelearningflashcards https://t.co/oHZwQZLJtQ',\n",
       "  'Thu Jul 06 17:09:00 +0000 2017'),\n",
       " ('MSE Vs MAE #machinelearningflashcards https://t.co/dn7QP5mLNt',\n",
       "  'Wed Jul 05 19:10:12 +0000 2017'),\n",
       " ('Explained Sum Of Squares #machinelearningflashcards https://t.co/P4axGoRTqF',\n",
       "  'Wed Jul 05 17:50:59 +0000 2017'),\n",
       " ('Non-Parametric Methods #machinelearningflashcards https://t.co/9UFyDv6c69',\n",
       "  'Tue Jul 04 19:36:50 +0000 2017'),\n",
       " ('Training Error Rate #machinelearningflashcards https://t.co/RkigF5Qvb9',\n",
       "  'Tue Jul 04 18:02:50 +0000 2017'),\n",
       " ('Random Forest Classification #machinelearningflashcards https://t.co/aLzGWvyAAH',\n",
       "  'Mon Jul 03 19:44:17 +0000 2017'),\n",
       " ('Model Complexity #machinelearningflashcards https://t.co/V9LVOEczrh',\n",
       "  'Mon Jul 03 17:59:35 +0000 2017'),\n",
       " ('Learning Curve #machinelearningflashcards https://t.co/NHk4ogDCNC',\n",
       "  'Fri Jun 30 19:37:23 +0000 2017'),\n",
       " ('Strategies When You Have High Variance #machinelearningflashcards https://t.co/CKPG3Wc3Vd',\n",
       "  'Fri Jun 30 17:31:40 +0000 2017'),\n",
       " ('Imputation Using kNN #machinelearningflashcards https://t.co/trrbK0ZvNY',\n",
       "  'Thu Jun 29 19:39:08 +0000 2017'),\n",
       " ('Tomek Links #machinelearningflashcards https://t.co/W1kbgTLHD7',\n",
       "  'Thu Jun 29 17:15:54 +0000 2017'),\n",
       " ('Bootstrap #machinelearningflashcards https://t.co/mGy4EFV6gx',\n",
       "  'Wed Jun 28 19:38:10 +0000 2017'),\n",
       " ('The Power Rule #machinelearningflashcards https://t.co/tCTXap2Mjb',\n",
       "  'Wed Jun 28 17:36:57 +0000 2017')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "last_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "for k in range(10):\n",
    "    r = api.search(q=\"#machinelearningflashcards\", count=100, until=last_date)\n",
    "    tweets += [(k._json['text'], k._json['created_at']) for k in r if k._json['user']['screen_name'] == 'chrisalbon' and \n",
    "                                                                          'media' in k._json['entities']]\n",
    "    dates = [dateutil.parser.parse(k[1]).strftime('%Y-%m-%d') for k in tweets]\n",
    "    last_date = min(dates)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-07T22:02:08.229281Z",
     "start_time": "2017-07-07T22:02:08.226809Z"
    }
   },
   "source": [
    "### Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-07T22:38:08.474126Z",
     "start_time": "2017-07-07T22:38:08.470334Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import urllib\n",
    "import time\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-07T22:36:54.301275Z",
     "start_time": "2017-07-07T22:36:52.712087Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.set_page_load_timeout(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-07T22:36:56.064337Z",
     "start_time": "2017-07-07T22:36:54.893962Z"
    }
   },
   "outputs": [],
   "source": [
    "query = '#machinelearningflashcards'\n",
    "# driver.get(\"https://twitter.com/search?q={}\".format(urllib.parse.quote(query)))\n",
    "driver.get(\"https://twitter.com/search?f=tweets&vertical=default&q={}\".format(urllib.parse.quote(query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-07T22:37:14.759973Z",
     "start_time": "2017-07-07T22:36:58.212901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more tweets (352) for this query\n"
     ]
    }
   ],
   "source": [
    "length = []\n",
    "while True:\n",
    "    time.sleep(np.random.randint(30,100)*0.01)\n",
    "    tweets_found = driver.find_elements_by_class_name('tweet') \n",
    "    driver.execute_script(\"return arguments[0].scrollIntoView();\", tweets_found[::-1][0])\n",
    "    # Stop the loop while no more found tweets \n",
    "    length.append(len(tweets_found))\n",
    "    if len(length) > 3 and (len(length) - len(set(length))) > 2:\n",
    "        print('No more tweets (%d) for this query' % len(tweets_found))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-07T23:01:40.637306Z",
     "start_time": "2017-07-07T23:01:36.488672Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for tweet in tweets_found:\n",
    "    tweet_dict = {}\n",
    "    tweet = tweet.get_attribute('innerHTML')\n",
    "    bs = BeautifulSoup(tweet.strip(), \"lxml\")\n",
    "    tweet_dict['username'] = bs.find('span', class_='username').text\n",
    "    tweet_dict['date'] = [v for k, v in bs.find('a', class_='tweet-timestamp').attrs.items() if 'title' in k][0]\n",
    "    tweet_dict['text'] = bs.find('p', class_='tweet-text').text\n",
    "    try:\n",
    "        tweet_dict['images'] = [k['src'] for k in bs.find('div', class_=\"AdaptiveMedia-container\").find_all('img')]\n",
    "    except:\n",
    "        tweet_dict['images'] = []\n",
    "    if len(tweet_dict['images']) > 0:\n",
    "        tweet_dict['text'] = tweet_dict['text'][:tweet_dict['text'].index('pic.twitter')-1]\n",
    "    tweets.append(tweet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-07T23:18:05.807104Z",
     "start_time": "2017-07-07T23:18:05.800429Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We keep only tweets by chrisalbon with pictures\n",
    "search_tweets = [tw for tw in tweets if tw['username'] == '@chrisalbon' and len(tw['images']) > 0]\n",
    "# He made multiple tweets on the same topic, we keep only the most recent tweets\n",
    "# We use the indexes of the reversed tweet list and dictionnaries to keep only key \n",
    "unique_search_index = sorted(list({t['text'].lower():i for i,t in list(enumerate(search_tweets))[::-1]}.values()))\n",
    "unique_search_tweets = [search_tweets[i] for i in unique_search_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workenv",
   "language": "python",
   "name": "workenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
